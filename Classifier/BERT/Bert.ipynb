{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "Bert.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nK0yh3Jr2JA0",
        "outputId": "0e464e5f-721a-46fd-9dd9-0c5c026f6e10"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install tensorflow_addons"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.10.3-py3-none-any.whl (2.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 5.2 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 34.7 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub>=0.0.12\n",
            "  Downloading huggingface_hub-0.0.17-py3-none-any.whl (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 538 kB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 42.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 47.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.17 pyyaml-5.4.1 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.10.3\n",
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.14.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXyrSgIp1xCm",
        "outputId": "9730ee01-d948-4e3c-d953-e08ab27acc7d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyTD0vtC2OLo"
      },
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import BertTokenizer, TFAutoModel, AlbertTokenizerFast\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "drive_loc = './drive/MyDrive/'\n",
        "\n",
        "#Load Data\n",
        "with open(f'{drive_loc}Word_Arrays_Article_Altered.pkl', 'rb') as f:\n",
        "    training, testing = pickle.load(f)\n",
        "\n",
        "seq_len = 50 #512\n",
        "batchs = 64\n",
        "\n",
        "model_name = 'bert-base-cased'\n",
        "#model_name = 'albert-base-v2'\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "#tokenizer = AlbertTokenizerFast.from_pretrained(model_name)\n",
        "ori_test = testing[:, 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_yR-VCW0I7Y"
      },
      "source": [
        "training_len = len(training)\n",
        "dataset = np.vstack((training, testing))\n",
        "dataset[:, 1] = dataset[:, 1].astype(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDcSHo0-sGjQ"
      },
      "source": [
        "lister = []\n",
        "for string in dataset[:, 0]:\n",
        "  lenner = len(string.split())\n",
        "  lister.append(lenner+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWc_n0GMsUXV",
        "outputId": "12f79696-d5bf-4d35-c512-af198bc70aa7"
      },
      "source": [
        "np.array(lister).std()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "413.3462714169685"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "v_EXFUUTMYTC"
      },
      "source": [
        "_input_ = training[-1,0]\n",
        "_tok_ =  tokenizer(_input_, \n",
        "                      max_length = seq_len, \n",
        "                      truncation=True,\n",
        "                      padding='max_length', \n",
        "                      add_special_tokens=True,\n",
        "                      return_tensors='np'\n",
        "                      )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "t_B_rQew3Tmi"
      },
      "source": [
        "def data_tokenised(data, tok, seq_len):\n",
        "    \n",
        "    samples = len(data)\n",
        "    num_labels = data[:, 1].astype(int).max()\n",
        "    \n",
        "    x_ids = np.zeros((samples, seq_len))\n",
        "    x_mask = np.zeros((samples, seq_len))\n",
        "    \n",
        "    for i in range(len(data)):\n",
        "        _input_ = data[i, 0]\n",
        "        _tok_ =  tok(_input_, \n",
        "                      max_length = seq_len, \n",
        "                      truncation=True,\n",
        "                      padding='max_length', \n",
        "                      add_special_tokens=True,\n",
        "                      return_tensors='np'\n",
        "                      )\n",
        "        x_ids[i, :] = _tok_['input_ids']\n",
        "        x_mask[i, :] = _tok_['attention_mask']\n",
        "    \n",
        "    lab = np.zeros((samples, num_labels+1))\n",
        "    \n",
        "    lab[np.arange(samples), data[:, 1].astype(int)] = 1\n",
        "    lab = lab[:, 1].reshape(-1, 1)\n",
        "    \n",
        "    return x_ids, x_mask, lab\n",
        "\n",
        "dataset = data_tokenised(dataset, tokenizer, seq_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "t712Vp9IKJmG"
      },
      "source": [
        "training = dataset[0][:training_len], dataset[1][:training_len], dataset[2][:training_len]\n",
        "testing = dataset[0][training_len:], dataset[1][training_len:], dataset[2][training_len:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "X0XgtYQaUbGh"
      },
      "source": [
        "X = {'input_ids':training[0],\n",
        "     'attention_mask':training[1]}\n",
        "y = training[2]\n",
        "\n",
        "X_test = {'input_ids':testing[0],\n",
        "          'attention_mask':testing[1]}\n",
        "y_test = testing[2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tabkOpEk3YIr"
      },
      "source": [
        "\n",
        "checkpoint_dir = f'{drive_loc}/Headline_Weights'\n",
        "#checkpoint_dir = './Checkpoints/weights'\n",
        "\n",
        "checkpoint = ModelCheckpoint(checkpoint_dir, monitor='val_accuracy', verbose=0, save_best_only=True, mode='auto')#, save_weights_only=True, mode='auto')  \n",
        "callbacks = [checkpoint]\n",
        "\n",
        "def create_model():\n",
        "  BERT = TFAutoModel.from_pretrained(model_name)\n",
        "\n",
        "  input_ids = tf.keras.layers.Input(shape=(seq_len, ), name='input_ids', dtype='int32')\n",
        "  mask = tf.keras.layers.Input(shape=(seq_len, ), name='attention_mask', dtype='int32')\n",
        "\n",
        "  embeddings = BERT.bert(input_ids, attention_mask=mask)['pooler_output'] #Try out index 0\n",
        "  #embeddings = BERT.albert(input_ids, attention_mask=mask)['pooler_output']\n",
        "\n",
        "  den_1 = tf.keras.layers.Dense(1000, activation='relu')(embeddings)\n",
        "  #den_2  = tf.keras.layers.Dense(1000, activation='relu')(den_1)\n",
        "  output = tf.keras.layers.Dense(1, activation='sigmoid')(den_1)\n",
        "\n",
        "  model = tf.keras.Model(inputs=[input_ids, mask], outputs=output)\n",
        "\n",
        "  #opt = tfa.optimizers.AdamW()\n",
        "  opt = tf.keras.optimizers.Adam(learning_rate = 1e-5)\n",
        "  loss = tf.keras.losses.BinaryCrossentropy()\n",
        "\n",
        "\n",
        "  model.compile(opt, loss=loss, metrics=['accuracy'])\n",
        "  #model.layers[0].trainable = False\n",
        "  #model.layers[1].trainable = False\n",
        "  #model.layers[2].trainable = False\n",
        "\n",
        "  return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "33e529351b7247988016b1881264a9d8"
          ]
        },
        "id": "DX5v9vT6bHXX",
        "outputId": "2023b09c-c2f1-4497-8932-34d1e8c45b93"
      },
      "source": [
        "tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "strategy = tf.distribute.TPUStrategy(tpu)\n",
        "\n",
        "# Create model\n",
        "with strategy.scope():\n",
        "    model = create_model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.58.31.58:8470\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.58.31.58:8470\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "33e529351b7247988016b1881264a9d8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/527M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1UtwMWwc1aV",
        "outputId": "2c268de8-8f5f-4a44-ad6c-e6de24e17f9e"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_ids (InputLayer)          [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "attention_mask (InputLayer)     [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bert (TFBertMainLayer)          TFBaseModelOutputWit 108310272   input_ids[0][0]                  \n",
            "                                                                 attention_mask[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1000)         769000      bert[0][1]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            1001        dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 109,080,273\n",
            "Trainable params: 109,080,273\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "lhRBIf4Je74z",
        "outputId": "69ecab23-0c4f-4df0-884d-8110931f33c2"
      },
      "source": [
        "\"\"\"\n",
        "history = model.fit(X, y,\n",
        "                    validation_data = (X_test, y_test),\n",
        "                    epochs = 1,\n",
        "                    batch_size = batchs,\n",
        "                    #callbacks = callbacks,\n",
        "                    verbose=1\n",
        "                    )\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nhistory = model.fit(X, y,\\n                    validation_data = (X_test, y_test),\\n                    epochs = 1,\\n                    batch_size = batchs,\\n                    #callbacks = callbacks,\\n                    verbose=1\\n                    )'"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLOEqLOgCxkt",
        "outputId": "6a412bce-a3bd-4c55-ce82-015d50fe639b"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "epochs = 50\n",
        "histories = {}\n",
        "\n",
        "best_results = 0\n",
        "\n",
        "for i in range(epochs):\n",
        "  print(f'Epoch {i}')\n",
        "  history = model.fit(X, y,\n",
        "                      validation_data = (X_test, y_test),\n",
        "                      epochs = 1,\n",
        "                      batch_size = batchs,\n",
        "                      verbose=1\n",
        "                      )\n",
        "  hist = history.history\n",
        "  for key in hist.keys():\n",
        "      if key not in histories:\n",
        "        histories[key] = []\n",
        "      else:\n",
        "        histories[key].append(hist[key][0])\n",
        "  \n",
        "  val_acc = hist['val_accuracy'][0]\n",
        "\n",
        "  if val_acc > best_results:\n",
        "    print('New Best')\n",
        "    preds = model.predict(X_test)\n",
        "\n",
        "    preds[preds>0.5] = 1\n",
        "    preds[preds<=0.5] = 0\n",
        "\n",
        "    best_results = val_acc\n",
        "\n",
        "    accuracy = accuracy_score(y_test, preds)\n",
        "    prec = precision_score(y_test, preds)\n",
        "    recall = recall_score(y_test, preds)\n",
        "    f1 = f1_score(y_test,preds)\n",
        "\n",
        "    \n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 50) dtype=float32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 50) dtype=float32>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None, 1) dtype=float32>]\n",
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 50) dtype=float32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 50) dtype=float32>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None, 1) dtype=float32>]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "109/109 [==============================] - ETA: 0s - loss: 0.4058 - accuracy: 0.8106"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 50) dtype=float32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 50) dtype=float32>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None, 1) dtype=float32>]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r109/109 [==============================] - 157s 679ms/step - loss: 0.4058 - accuracy: 0.8106 - val_loss: 0.2398 - val_accuracy: 0.9112\n",
            "New Best\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 50) dtype=float32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 50) dtype=float32>]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "109/109 [==============================] - 9s 86ms/step - loss: 0.2239 - accuracy: 0.9143 - val_loss: 0.2757 - val_accuracy: 0.8912\n",
            "Epoch 2\n",
            "109/109 [==============================] - 9s 86ms/step - loss: 0.1629 - accuracy: 0.9372 - val_loss: 0.2220 - val_accuracy: 0.9190\n",
            "New Best\n",
            "Epoch 3\n",
            "109/109 [==============================] - 9s 86ms/step - loss: 0.1041 - accuracy: 0.9620 - val_loss: 0.2503 - val_accuracy: 0.9285\n",
            "New Best\n",
            "Epoch 4\n",
            "109/109 [==============================] - 9s 87ms/step - loss: 0.0674 - accuracy: 0.9776 - val_loss: 0.2686 - val_accuracy: 0.9224\n",
            "Epoch 5\n",
            "109/109 [==============================] - 9s 86ms/step - loss: 0.0458 - accuracy: 0.9857 - val_loss: 0.3238 - val_accuracy: 0.9250\n",
            "Epoch 6\n",
            "109/109 [==============================] - 9s 87ms/step - loss: 0.0372 - accuracy: 0.9889 - val_loss: 0.3091 - val_accuracy: 0.9289\n",
            "New Best\n",
            "Epoch 7\n",
            "109/109 [==============================] - 9s 86ms/step - loss: 0.0340 - accuracy: 0.9900 - val_loss: 0.3093 - val_accuracy: 0.9289\n",
            "Epoch 8\n",
            "109/109 [==============================] - 9s 86ms/step - loss: 0.0286 - accuracy: 0.9908 - val_loss: 0.3702 - val_accuracy: 0.9177\n",
            "Epoch 9\n",
            "109/109 [==============================] - 9s 87ms/step - loss: 0.0201 - accuracy: 0.9942 - val_loss: 0.3853 - val_accuracy: 0.9172\n",
            "Epoch 10\n",
            "109/109 [==============================] - 9s 86ms/step - loss: 0.0202 - accuracy: 0.9939 - val_loss: 0.3295 - val_accuracy: 0.9298\n",
            "New Best\n",
            "Epoch 11\n",
            "109/109 [==============================] - 9s 86ms/step - loss: 0.0248 - accuracy: 0.9918 - val_loss: 0.3492 - val_accuracy: 0.9302\n",
            "New Best\n",
            "Epoch 12\n",
            "109/109 [==============================] - 10s 93ms/step - loss: 0.0236 - accuracy: 0.9915 - val_loss: 0.3229 - val_accuracy: 0.9298\n",
            "Epoch 13\n",
            "109/109 [==============================] - 9s 86ms/step - loss: 0.0135 - accuracy: 0.9965 - val_loss: 0.3742 - val_accuracy: 0.9298\n",
            "Epoch 14\n",
            "109/109 [==============================] - 9s 86ms/step - loss: 0.0101 - accuracy: 0.9968 - val_loss: 0.3744 - val_accuracy: 0.9302\n",
            "Epoch 15\n",
            "109/109 [==============================] - 9s 86ms/step - loss: 0.0141 - accuracy: 0.9954 - val_loss: 0.4083 - val_accuracy: 0.9272\n",
            "Epoch 16\n",
            "109/109 [==============================] - 9s 86ms/step - loss: 0.0124 - accuracy: 0.9955 - val_loss: 0.4546 - val_accuracy: 0.9177\n",
            "Epoch 17\n",
            "109/109 [==============================] - 9s 86ms/step - loss: 0.0112 - accuracy: 0.9962 - val_loss: 0.4364 - val_accuracy: 0.9281\n",
            "Epoch 18\n",
            "109/109 [==============================] - 9s 86ms/step - loss: 0.0126 - accuracy: 0.9958 - val_loss: 0.4174 - val_accuracy: 0.9242\n",
            "Epoch 19\n",
            "109/109 [==============================] - 9s 86ms/step - loss: 0.0145 - accuracy: 0.9954 - val_loss: 0.3772 - val_accuracy: 0.9289\n",
            "Epoch 20\n",
            "109/109 [==============================] - 9s 87ms/step - loss: 0.0083 - accuracy: 0.9971 - val_loss: 0.4511 - val_accuracy: 0.9229\n",
            "Epoch 21\n",
            "109/109 [==============================] - 10s 87ms/step - loss: 0.0086 - accuracy: 0.9964 - val_loss: 0.4126 - val_accuracy: 0.9281\n",
            "Epoch 22\n",
            "109/109 [==============================] - 9s 87ms/step - loss: 0.0096 - accuracy: 0.9967 - val_loss: 0.4158 - val_accuracy: 0.9285\n",
            "Epoch 23\n",
            "109/109 [==============================] - 9s 86ms/step - loss: 0.0082 - accuracy: 0.9965 - val_loss: 0.4502 - val_accuracy: 0.9276\n",
            "Epoch 24\n",
            "109/109 [==============================] - 9s 87ms/step - loss: 0.0077 - accuracy: 0.9968 - val_loss: 0.4377 - val_accuracy: 0.9237\n",
            "Epoch 25\n",
            "109/109 [==============================] - 9s 86ms/step - loss: 0.0054 - accuracy: 0.9978 - val_loss: 0.4486 - val_accuracy: 0.9268\n",
            "Epoch 26\n",
            "109/109 [==============================] - 9s 86ms/step - loss: 0.0092 - accuracy: 0.9964 - val_loss: 0.4332 - val_accuracy: 0.9276\n",
            "Epoch 27\n",
            "109/109 [==============================] - 9s 87ms/step - loss: 0.0058 - accuracy: 0.9973 - val_loss: 0.4459 - val_accuracy: 0.9320\n",
            "New Best\n",
            "Epoch 28\n",
            "109/109 [==============================] - 10s 92ms/step - loss: 0.0059 - accuracy: 0.9971 - val_loss: 0.5653 - val_accuracy: 0.9081\n",
            "Epoch 29\n",
            "109/109 [==============================] - 9s 87ms/step - loss: 0.0124 - accuracy: 0.9952 - val_loss: 0.4310 - val_accuracy: 0.9294\n",
            "Epoch 30\n",
            "109/109 [==============================] - 9s 87ms/step - loss: 0.0095 - accuracy: 0.9962 - val_loss: 0.4239 - val_accuracy: 0.9311\n",
            "Epoch 31\n",
            "109/109 [==============================] - 9s 86ms/step - loss: 0.0075 - accuracy: 0.9973 - val_loss: 0.4292 - val_accuracy: 0.9298\n",
            "Epoch 32\n",
            "109/109 [==============================] - 9s 86ms/step - loss: 0.0087 - accuracy: 0.9964 - val_loss: 0.4255 - val_accuracy: 0.9315\n",
            "Epoch 33\n",
            "109/109 [==============================] - 9s 87ms/step - loss: 0.0065 - accuracy: 0.9967 - val_loss: 0.4633 - val_accuracy: 0.9172\n",
            "Epoch 34\n",
            "109/109 [==============================] - 9s 86ms/step - loss: 0.0077 - accuracy: 0.9964 - val_loss: 0.4423 - val_accuracy: 0.9337\n",
            "New Best\n",
            "Epoch 35\n",
            "109/109 [==============================] - 9s 86ms/step - loss: 0.0056 - accuracy: 0.9977 - val_loss: 0.4425 - val_accuracy: 0.9320\n",
            "Epoch 36\n",
            "109/109 [==============================] - 9s 86ms/step - loss: 0.0062 - accuracy: 0.9977 - val_loss: 0.4643 - val_accuracy: 0.9320\n",
            "Epoch 37\n",
            "109/109 [==============================] - 10s 88ms/step - loss: 0.0064 - accuracy: 0.9974 - val_loss: 0.4592 - val_accuracy: 0.9220\n",
            "Epoch 38\n",
            "109/109 [==============================] - 10s 92ms/step - loss: 0.0100 - accuracy: 0.9961 - val_loss: 0.3863 - val_accuracy: 0.9289\n",
            "Epoch 39\n",
            "109/109 [==============================] - 9s 87ms/step - loss: 0.0054 - accuracy: 0.9978 - val_loss: 0.4522 - val_accuracy: 0.9276\n",
            "Epoch 40\n",
            "109/109 [==============================] - 10s 87ms/step - loss: 0.0040 - accuracy: 0.9984 - val_loss: 0.4910 - val_accuracy: 0.9255\n",
            "Epoch 41\n",
            "109/109 [==============================] - 9s 86ms/step - loss: 0.0039 - accuracy: 0.9980 - val_loss: 0.5191 - val_accuracy: 0.9242\n",
            "Epoch 42\n",
            "109/109 [==============================] - 9s 87ms/step - loss: 0.0066 - accuracy: 0.9970 - val_loss: 0.4627 - val_accuracy: 0.9281\n",
            "Epoch 43\n",
            "109/109 [==============================] - 9s 87ms/step - loss: 0.0044 - accuracy: 0.9980 - val_loss: 0.5302 - val_accuracy: 0.9255\n",
            "Epoch 44\n",
            "109/109 [==============================] - 9s 87ms/step - loss: 0.0045 - accuracy: 0.9984 - val_loss: 0.6925 - val_accuracy: 0.9016\n",
            "Epoch 45\n",
            "109/109 [==============================] - 10s 87ms/step - loss: 0.0062 - accuracy: 0.9968 - val_loss: 0.5103 - val_accuracy: 0.9298\n",
            "Epoch 46\n",
            "109/109 [==============================] - 10s 88ms/step - loss: 0.0048 - accuracy: 0.9973 - val_loss: 0.5393 - val_accuracy: 0.9311\n",
            "Epoch 47\n",
            "109/109 [==============================] - 10s 88ms/step - loss: 0.0098 - accuracy: 0.9962 - val_loss: 0.4634 - val_accuracy: 0.9155\n",
            "Epoch 48\n",
            "109/109 [==============================] - 9s 87ms/step - loss: 0.0047 - accuracy: 0.9981 - val_loss: 0.5298 - val_accuracy: 0.9246\n",
            "Epoch 49\n",
            "109/109 [==============================] - 9s 87ms/step - loss: 0.0044 - accuracy: 0.9980 - val_loss: 0.5092 - val_accuracy: 0.9289\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ym0HiLnFZRUy"
      },
      "source": [
        "#Results\n",
        "#hist = model.history\n",
        "\n",
        "histories['Metrics'] = {'Accuracy':accuracy,\n",
        "                        'Precision_Score':prec,\n",
        "                        'Recall':recall,\n",
        "                        'f1_score':f1}\n",
        "\n",
        "\n",
        "#with open(f'{drive_loc}/History-Headlines-Final.pkl', 'wb') as f:\n",
        "    #pickle.dump(histories, f)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}